# Referencia RÃ¡pida: Almacenamiento de Datos en LA Referencia v5.0

## ğŸ¯ Quick Reference Sheet

### DÃ³nde se guarda cada cosa

| QuÃ© | DÃ³nde | CÃ³mo | Acceso | Ejemplo |
|-----|-------|------|--------|---------|
| **Metadata Snapshot** | PostgreSQL | `NetworkSnapshot` entity | `ISnapshotStore` | `snapshotStore.createSnapshot(network)` |
| **Metadata Records (XML)** | Filesystem | XML comprimido con GZIP | `IMetadataStore` | `metadataStore.getMetadata(snapshot, hash)` |
| **Records OAI** | Parquet | Binario comprimido | `OAIRecordParquetRepository` | `repo.getIterator(metadata)` |
| **ValidaciÃ³n Stats** | JSON (FS) | `validation-stats.json` | `ValidationStatParquetRepository` | `repo.getSnapshotValidationStats(metadata)` |
| **ValidaciÃ³n Records** | Parquet | Records con RuleFacts anidados | `ValidationRecordManager` | `manager.readNext()` |
| **Ãndice Ligero** | Parquet | `validation_index.parquet` | `ValidationRecordManager` | `manager.loadLightweightIndex(status)` |
| **Logs** | Texto | Plain text append | `SnapshotLogService` | `service.addEntry(snapshotId, msg)` |

---

## ï¿½ Metadata - Estructura Dual-Layer

### Capa 1: PostgreSQL (Metadata Estructural Ãšnicamente)
```sql
-- Tabla network_snapshot (referencias a archivos Parquet)
CREATE TABLE network_snapshot (
    id BIGINT PRIMARY KEY,
    network_id BIGINT NOT NULL,
    size INT,                          -- Total records (denormalizado de catÃ¡logo Parquet)
    valid_size INT,                    -- Valid records (denormalizado de stats JSON)
    status VARCHAR(50),                -- HARVESTING_IN_PROGRESS, etc.
    start_time TIMESTAMP,              -- Harvest start
    end_time TIMESTAMP,                -- Harvest end
    ...
);

-- NOTA: El catÃ¡logo OAI NO estÃ¡ en BD
-- Los registros OAI se guardan en Parquet:
-- {basePath}/{NETWORK}/snapshots/snapshot_{ID}/catalog/oai_records_batch_*.parquet
```

### Capa 2: Filesystem (Metadata Detallada + CatÃ¡logo OAI)

#### 2.1 Metadata XML Comprimido
```
{basePath}/{NETWORK}/metadata/{L1}/{L2}/{L3}/{HASH}.xml.gz

Ejemplo:
/data/lareferencia/IBICT/metadata/A/B/C/ABCDEF123456789.xml.gz
/data/lareferencia/LA_REFERENCIA/metadata/X/Y/Z/XYZABC987654321.xml.gz
```

**CaracterÃ­sticas**:
- âœ… **DeduplicaciÃ³n**: Mismo XML = mismo hash
- âœ… **Particionamiento**: 3 niveles (4,096 particiones)
- âœ… **BÃºsqueda O(1)**: Hash-based, sin scanning
- âœ… **CompresiÃ³n**: 70-80% ahorro con GZIP
- âœ… **Isolation**: Separado por network

#### 2.2 CatÃ¡logo OAI (Parquet - Inmutable)
```
{basePath}/{NETWORK}/snapshots/snapshot_{ID}/catalog/oai_records_batch_*.parquet

Estructura:
- id: String - Hash MD5 del identifier (PK)
- identifier: String - Identificador OAI Ãºnico
- datestamp: Timestamp - Fecha de Ãºltima modificaciÃ³n
- original_metadata_hash: String - Hash MD5 del XML original cosechado
- deleted: Boolean - Flag de eliminaciÃ³n
```

**CaracterÃ­sticas**:
- âœ… **Inmutable**: Se escribe UNA SOLA VEZ, nunca se actualiza
- âœ… **Sin estado de validaciÃ³n**: Solo datos del harvesting
- âœ… **Batching**: Auto-flush cada 10,000 records
- âœ… **CompresiÃ³n SNAPPY**: ~8 bytes/record
- âœ… **Lectura lazy**: Streaming sin cargar todo en memoria

### API: IMetadataStore
```java
// Guardar metadata y obtener hash
String storeAndReturnHash(SnapshotMetadata snapshotMetadata, String xmlContent);

// Recuperar metadata por hash
String getMetadata(SnapshotMetadata snapshotMetadata, String hash);

// Limpieza
Boolean cleanAndOptimizeStore();
```

### Flujo de IntegraciÃ³n

**Harvesting (CatÃ¡logo OAI + Metadata XML)**:
```
Harvester
   â†“
1. xmlMetadata = harvester.fetchMetadata(identifier)
   â†“
2. metadataHash = metadataStore.storeAndReturnHash(snapshot, xmlMetadata)
   â†’ FS: /data/lareferencia/.../metadata/{L1}/{L2}/{L3}/{HASH}.xml.gz
   
3. oaiRecord = OAIRecord.create(identifier, datestamp, metadataHash, deleted)
   â†’ Construye record del catÃ¡logo OAI
   
4. oaiRecordRepository.saveRecord(snapshotId, oaiRecord)
   â†’ Parquet: snapshot_{ID}/catalog/oai_records_batch_*.parquet (buffered)
   
5. oaiRecordRepository.finalizeSnapshot(snapshotId)
   â†’ Flush final de catÃ¡logo (cierra archivos Parquet)
```

**Lectura/ValidaciÃ³n**:
```
Validator
   â†“
1. oaiRecord = oaiRecordRepository.getIterator(snapshotMetadata)
   â†’ Parquet: Lee catalogo desde oai_records_batch_*.parquet (streaming)
   
2. xmlContent = metadataStore.getMetadata(snapshot, oaiRecord.getOriginalMetadataHash())
   â†’ FS: /data/lareferencia/.../metadata/{L1}/{L2}/{L3}/{HASH}.xml.gz
   
3. validationResult = validator.validate(xmlContent)
   â†’ Procesa validaciÃ³n
```

---

## ï¿½ğŸ“‚ Estructura de Directorios

```
---

## ğŸ“‚ Estructura de Directorios

### ğŸ—‚ï¸ OrganizaciÃ³n General

Todo el almacenamiento sigue una estructura unificada basada en el `basePath` y el network acronym:

```
{basePath}/
â””â”€â”€ {NETWORK}/                        â† Sanitizado (espaciosâ†’_, mayÃºsculas)
    â”œâ”€â”€ metadata/                     â† Metadata XML (IMetadataStore)
    â”‚   â””â”€â”€ {L1}/{L2}/{L3}/          â† Particionamiento de 3 niveles
    â”‚       â””â”€â”€ {HASH}.xml.gz        â† Archivo comprimido
    â””â”€â”€ snapshots/                    â† Records OAI + ValidaciÃ³n + Logs
        â””â”€â”€ snapshot_{ID}/
            â”œâ”€â”€ catalog/              â† OAI Records (Parquet)
            â”œâ”€â”€ validation/           â† ValidaciÃ³n (Parquet)
            â””â”€â”€ snapshot.log          â† Logs (Texto)
```

### ğŸ“ Metadata XML (Comprimida con GZIP)

**UbicaciÃ³n**: `{basePath}/{NETWORK}/metadata/{L1}/{L2}/{L3}/{HASH}.xml.gz`

**Particionamiento**: 
- 3 niveles basados en los primeros 3 caracteres del hash
- Total de particiones posibles: 16Â³ = 4,096
- Ejemplo: Hash `ABCDEF123...` â†’ ParticiÃ³n `A/B/C/`

**Ejemplo real**:
```
/data/lareferencia/IBICT/metadata/
â”œâ”€â”€ A/
â”‚   â”œâ”€â”€ B/
â”‚   â”‚   â”œâ”€â”€ C/
â”‚   â”‚   â”‚   â”œâ”€â”€ ABCDEF123456789ABC.xml.gz
â”‚   â”‚   â”‚   â””â”€â”€ ABCABC987654321XYZ.xml.gz
â”‚   â”‚   â””â”€â”€ D/
â”‚   â”‚       â””â”€â”€ ABDABC111222333XYZ.xml.gz
â”‚   â””â”€â”€ X/
â”‚       â””â”€â”€ Y/
â”‚           â””â”€â”€ Z/
â”‚               â””â”€â”€ AXYZZZ999888777ABC.xml.gz
â”œâ”€â”€ F/
â”‚   â””â”€â”€ 0/
â”‚       â””â”€â”€ 0/
â”‚           â””â”€â”€ F00ABC123456789DEF.xml.gz
â””â”€â”€ ... (mÃ¡s particiones)
```

**CaracterÃ­sticas**:
- âœ… DeduplicaciÃ³n: Mismo contenido XML = mismo hash = un solo archivo
- âœ… BÃºsqueda O(1): Lookup directo por hash sin scanning
- âœ… CompresiÃ³n GZIP: ~70-80% reducciÃ³n de espacio
- âœ… Network isolation: Cada red en su directorio

### ğŸ“Š Records OAI (Parquet)

**UbicaciÃ³n**: `{basePath}/{NETWORK}/snapshots/snapshot_{ID}/catalog/oai_records_batch_*.parquet`

**Estructura de batches**:
- Auto-flush cada 10,000 records (configurable)
- Archivos secuenciales: `batch_1.parquet`, `batch_2.parquet`, ...
- CompresiÃ³n SNAPPY

**Ejemplo real**:
```
/data/lareferencia/IBICT/snapshots/snapshot_101/catalog/
â”œâ”€â”€ oai_records_batch_1.parquet       (10,000 records, ~8 MB)
â”œâ”€â”€ oai_records_batch_2.parquet       (10,000 records, ~8 MB)
â””â”€â”€ oai_records_batch_3.parquet       (5,234 records, ~4 MB)

Total: 25,234 records en 3 archivos (20 MB)
```

### âœ… ValidaciÃ³n (Dual-Layer: JSON Stats + Parquet Records con Facts Anidados)

**UbicaciÃ³n Base**: `{basePath}/{NETWORK}/snapshots/snapshot_{ID}/validation/`

La validaciÃ³n usa una **arquitectura eficiente de 2 capas** que elimina la explosiÃ³n de filas:

#### Layer 1: EstadÃ­sticas Agregadas (JSON)
**Archivo**: `validation-stats.json`

Contiene estadÃ­sticas precomputadas guardadas **UNA SOLA VEZ**:
```json
{
  "totalRecords": 25234,
  "validRecords": 20100,
  "invalidRecords": 5134,
  "transformedRecords": 18500,
  "ruleStats": {
    "1": { "validCount": 25000, "invalidCount": 234 },
    "2": { "validCount": 24500, "invalidCount": 734 }
  },
  "facets": {
    "record_is_valid": { "true": 20100, "false": 5134 }
  }
}
```

**Ventajas**:
- âœ… Consultas ultra-rÃ¡pidas (<1ms)
- âœ… Formato legible para debugging
- âœ… No requiere PostgreSQL ni cÃ¡lculos complejos

#### Layer 2: Records de ValidaciÃ³n con Rule Facts Anidados (Parquet)
**Archivos**: `records_batch_*.parquet`

**Estructura**: 1 fila por RECORD con RuleFacts anidados dentro

**Schema Parquet** (estructura anidada):
```
RecordValidation:
â”œâ”€â”€ identifier: String (required)
â”œâ”€â”€ record_id: String (required, PK)
â”œâ”€â”€ datestamp: Timestamp (optional)
â”œâ”€â”€ record_is_valid: Boolean (required)
â”œâ”€â”€ is_transformed: Boolean (required)
â”œâ”€â”€ published_metadata_hash: String (optional)
â””â”€â”€ rule_facts_list: List (optional, nested)
    â””â”€â”€ fact: Struct (repeated)
        â”œâ”€â”€ rule_id: Int (required)
        â”œâ”€â”€ is_valid: Boolean (required)
        â”œâ”€â”€ valid_occurrences: List<String> (optional)
        â””â”€â”€ invalid_occurrences: List<String> (optional)
```

**Ejemplo de record**:
```json
{
  "record_id": "abc123",
  "identifier": "oai:example.org/123",
  "record_is_valid": true,
  "is_transformed": false,
  "rule_facts_list": [
    {
      "rule_id": 1,
      "is_valid": true,
      "valid_occurrences": ["value1", "value2"]
    },
    {
      "rule_id": 2,
      "is_valid": false,
      "invalid_occurrences": ["bad_value"]
    }
  ]
}
```

**Archivos batch**:
```
records_batch_1.parquet  (10,000 records con facts anidados, ~5 MB)
records_batch_2.parquet  (10,000 records con facts anidados, ~5 MB)
records_batch_3.parquet  (5,234 records con facts anidados, ~2.5 MB)

Total: 25,234 records en 3 archivos (~12.5 MB)
```

**Ventajas de la estructura anidada**:
- âœ… ReducciÃ³n ~88% de espacio vs fact table separada
- âœ… PaginaciÃ³n correcta: 20 filas = 20 records completos
- âœ… Consultas eficientes con proyecciÃ³n de columnas Parquet
- âœ… Lectura lazy: Solo lee rule_facts cuando se necesita
- âœ… CompresiÃ³n SNAPPY + dictionary encoding

**Ãndice ligero adicional**:
**Archivo**: `validation_index.parquet`

Contiene solo campos esenciales (sin rule_facts) para queries rÃ¡pidas:
- `record_id`, `identifier`, `datestamp`
- `record_is_valid`, `is_transformed`
- `published_metadata_hash`

**Uso**: Filtrado rÃ¡pido sin leer rule facts completos (~35 bytes/record)

### ğŸ“‹ Logs (Texto Plano)

**UbicaciÃ³n**: `{basePath}/{NETWORK}/snapshots/snapshot_{ID}/snapshot.log`

**Formato**:
```
[2025-11-12 10:30:15.123] HARVEST STARTED - network=IBICT
[2025-11-12 10:30:20.456] Record harvested: oai:example.org/123
[2025-11-12 10:35:45.789] HARVEST COMPLETED - 25,234 records
[2025-11-12 10:36:00.012] VALIDATION STARTED
[2025-11-12 10:40:30.567] VALIDATION COMPLETED - 15,234 valid
```

**CaracterÃ­sticas**:
- Append-only (nunca se sobrescribe)
- Timestamp con milisegundos
- Paginado en lectura (API REST)

### ğŸŒ² Ãrbol Completo - Ejemplo con 2 Snapshots

```
/data/lareferencia/
â”œâ”€â”€ IBICT/                                         â† Network
â”‚   â”œâ”€â”€ metadata/                                  â† Metadata XML
â”‚   â”‚   â”œâ”€â”€ A/
â”‚   â”‚   â”‚   â””â”€â”€ B/
â”‚   â”‚   â”‚       â””â”€â”€ C/
â”‚   â”‚   â”‚           â”œâ”€â”€ ABCDEF123456789ABC.xml.gz  (500 bytes)
â”‚   â”‚   â”‚           â””â”€â”€ ABCABC987654321XYZ.xml.gz  (480 bytes)
â”‚   â”‚   â”œâ”€â”€ F/
â”‚   â”‚   â”‚   â””â”€â”€ 0/
â”‚   â”‚   â”‚       â””â”€â”€ 0/
â”‚   â”‚   â”‚           â””â”€â”€ F00ABC123456789DEF.xml.gz  (510 bytes)
â”‚   â”‚   â””â”€â”€ ... (mÃ¡s particiones con ~25,000 archivos)
â”‚   â”‚
â”‚   â””â”€â”€ snapshots/                                 â† Snapshots
â”‚       â”œâ”€â”€ snapshot_101/                          â† Snapshot 1
â”‚       â”‚   â”œâ”€â”€ metadata.json                      (Metadata de snapshot, ~2 KB)
â”‚       â”‚   â”œâ”€â”€ catalog/                           â† OAI Records
â”‚       â”‚   â”‚   â”œâ”€â”€ oai_records_batch_1.parquet    (10,000 records, 8 MB)
â”‚       â”‚   â”‚   â”œâ”€â”€ oai_records_batch_2.parquet    (10,000 records, 8 MB)
â”‚       â”‚   â”‚   â””â”€â”€ oai_records_batch_3.parquet    (5,234 records, 4 MB)
â”‚       â”‚   â”œâ”€â”€ validation/                        â† ValidaciÃ³n (2 layers: JSON + Parquet anidado)
â”‚       â”‚   â”‚   â”œâ”€â”€ validation-stats.json          (EstadÃ­sticas agregadas, ~5 KB)
â”‚       â”‚   â”‚   â”œâ”€â”€ validation_index.parquet       (Ãndice ligero sin facts, ~900 KB)
â”‚       â”‚   â”‚   â”œâ”€â”€ records_batch_1.parquet        (10,000 records con facts anidados, ~5 MB)
â”‚       â”‚   â”‚   â”œâ”€â”€ records_batch_2.parquet        (10,000 records con facts anidados, ~5 MB)
â”‚       â”‚   â”‚   â””â”€â”€ records_batch_3.parquet        (5,234 records con facts anidados, ~2.5 MB)
â”‚       â”‚   â””â”€â”€ snapshot.log                       (25,234 entries, 250 KB)
â”‚       â”‚
â”‚       â””â”€â”€ snapshot_102/                          â† Snapshot 2
â”‚           â”œâ”€â”€ metadata.json                      (~2 KB)
â”‚           â”œâ”€â”€ catalog/
â”‚           â”‚   â”œâ”€â”€ oai_records_batch_1.parquet    (10,000 records, 8 MB)
â”‚           â”‚   â””â”€â”€ oai_records_batch_2.parquet    (8,500 records, 7 MB)
â”‚           â”œâ”€â”€ validation/
â”‚           â”‚   â”œâ”€â”€ validation-stats.json          (~5 KB)
â”‚           â”‚   â”œâ”€â”€ validation_index.parquet       (~750 KB)
â”‚           â”‚   â”œâ”€â”€ records_batch_1.parquet        (10,000 con facts, ~5 MB)
â”‚           â”‚   â””â”€â”€ records_batch_2.parquet        (8,500 con facts, ~4 MB)
â”‚           â””â”€â”€ snapshot.log                       (18,500 entries, 190 KB)
â”‚
â””â”€â”€ LA_REFERENCIA/                                 â† Otra Network
    â”œâ”€â”€ metadata/
    â”‚   â””â”€â”€ ... (similar estructura)
    â””â”€â”€ snapshots/
        â””â”€â”€ ... (similar estructura)
```
â””â”€â”€ LA_REFERENCIA/                                 â† Otra Network
    â”œâ”€â”€ metadata/
    â”‚   â””â”€â”€ ... (similar estructura)
    â””â”€â”€ snapshots/
        â””â”€â”€ ... (similar estructura)
```

### ğŸ”— RelaciÃ³n entre Componentes

```
PostgreSQL (network_snapshot)
    â†“ id=101, network_id=5, size=25234
    â”‚
    â”œâ”€â”€â†’ Filesystem: /data/lareferencia/IBICT/snapshots/snapshot_101/
    â”‚                â”œâ”€â”€ catalog/*.parquet (CatÃ¡logo OAI inmutable)
    â”‚                â”œâ”€â”€ validation/*.parquet (ValidaciÃ³n)
    â”‚                â””â”€â”€ snapshot.log
    â”‚
Parquet CatÃ¡logo OAI (snapshot_101/catalog/oai_records_batch_*.parquet)
    â†“ record: identifier="oai:ex.org/123", original_metadata_hash="ABCDEF123..."
    â”‚
    â””â”€â”€â†’ Filesystem: /data/lareferencia/IBICT/metadata/A/B/C/ABCDEF123456789ABC.xml.gz
         (XML comprimido - compartido entre snapshots con mismo contenido)
```

### ğŸ“ TamaÃ±os Estimados (25,000 records)

| Componente | UbicaciÃ³n | TamaÃ±o | Notas |
|------------|-----------|--------|-------|
| **Metadata XML** | `{basePath}/{NETWORK}/metadata/` | ~10-12 MB | Comprimido GZIP, deduplicado |
| **Snapshot Metadata** | `{basePath}/{NETWORK}/snapshots/snapshot_{ID}/metadata.json` | ~2 KB | JSON estructural |
| **OAI Records** | `{basePath}/{NETWORK}/snapshots/snapshot_{ID}/catalog/` | ~20 MB | Parquet SNAPPY, 3 batches |
| **Validation Stats** | `{basePath}/{NETWORK}/snapshots/snapshot_{ID}/validation/validation-stats.json` | ~5 KB | JSON agregado |
| **Validation Index** | `{basePath}/{NETWORK}/snapshots/snapshot_{ID}/validation/validation_index.parquet` | ~900 KB | Ãndice ligero sin facts |
| **Validation Records** | `{basePath}/{NETWORK}/snapshots/snapshot_{ID}/validation/records_*.parquet` | ~12.5 MB | Con RuleFacts anidados |
| **Logs** | `{basePath}/{NETWORK}/snapshots/snapshot_{ID}/snapshot.log` | ~250 KB | Texto plano |
| **PostgreSQL** | BD | ~1-2 MB | Metadata estructural |
| **TOTAL** | | **~45-48 MB** | Por snapshot completo |

**ProyecciÃ³n**:
- 100 snapshots = ~4.7 GB
- 1,000 snapshots = ~47 GB
- DeduplicaciÃ³n de metadata ahorra ~30-50% del espacio total

**Desglose por capas**:
- 26% Metadata XML (deduplicado entre snapshots)
- 42% OAI Records (Parquet catalog)
- 28% ValidaciÃ³n (JSON stats + Ã­ndice + records con facts anidados)
- 3% Logs
- 1% Metadata estructural (JSON + PostgreSQL)
- 1% Metadata estructural (JSON + PostgreSQL)

### ğŸ”§ SanitizaciÃ³n de Network Acronym

El nombre del directorio de red se sanitiza automÃ¡ticamente:

| Original | Sanitizado | Ejemplo Ruta |
|----------|------------|--------------|
| `br` | `BR` | `/data/lareferencia/BR/` |
| `LA Referencia` | `LA_REFERENCIA` | `/data/lareferencia/LA_REFERENCIA/` |
| `mx-unam` | `MX-UNAM` | `/data/lareferencia/MX-UNAM/` |
| `test@123` | `TEST_123` | `/data/lareferencia/TEST_123/` |

**Reglas**:
- MayÃºsculas
- Solo permitidos: `A-Z`, `0-9`, `-`, `_`
- Todo lo demÃ¡s â†’ `_`

---

## ğŸ”„ Ciclo de Vida

### 1ï¸âƒ£ Harvesting
```
1. snapshotStore.createSnapshot(network)
   â†’ BD: INSERT snapshot (status=HARVESTING_IN_PROGRESS)
   
2. oaiRecordRepository.initializeSnapshot(snapshotMetadata)
   â†’ FS: mkdir catalog/
   
3. saveRecord() Ã— N
   â†’ FS: Append to buffer
   â†’ Auto-flush: batch_1.parquet, batch_2.parquet, ...
   â†’ BD: incrementSnapshotSize()
   
4. oaiRecordRepository.finalizeSnapshot(snapshotId)
   â†’ FS: Flush final, close last batch
   
5. snapshotStore.updateSnapshotStatus(..., HARVESTING_FINISHED_VALID)
   â†’ BD: UPDATE snapshot SET status=...
```

### 2ï¸âƒ£ ValidaciÃ³n
```
1. validationStatRepository.initializeSnapshot(snapshotMetadata)
   â†’ FS: mkdir validation/
   â†’ FS: Crear metadata inicial (SnapshotValidationStats vacÃ­o)
   
2. validationService.addObservation() Ã— N
   â†’ FS: saveRecordAndFacts() incremental
   â†’ Auto-flush cada 10k records
   â†’ Actualiza stats acumulativos en memoria
   
3. validationStatRepository.finalizeSnapshot(snapshotId)
   â†’ FS: Flush final de buffers pendientes
   â†’ FS: Escribir validation-stats.json (estadÃ­sticas finales)
   â†’ Cierre de writers
   
4. snapshotStore.updateSnapshotStatus(..., VALIDATION_FINISHED_VALID)
   â†’ BD: UPDATE snapshot SET status=...
```

**Archivos generados**:
- `validation-stats.json` (Layer 1: estadÃ­sticas agregadas)
- `validation_index.parquet` (Ãndice ligero sin rule_facts)
- `records_batch_*.parquet` (Layer 2: records con RuleFacts anidados)

---

## ğŸ“Š Campos en PostgreSQL

### `network_snapshot`
```sql
id (BIGINT PRIMARY KEY)
network_id (BIGINT FK)
size (INT) -- Total records harvested
valid_size (INT) -- Records valid after validation
transformed_size (INT) -- Records transformed
status (ENUM) -- HARVESTING_IN_PROGRESS, HARVESTING_FINISHED_VALID, ...
index_status (ENUM) -- UNKNOWN, PENDING, INDEXED, ...
start_time (TIMESTAMP) -- Harvest start
end_time (TIMESTAMP) -- Harvest end
last_incremental_time (TIMESTAMP) -- Last OAI-PMH incremental
previous_snapshot_id (BIGINT FK) -- Link to previous snapshot
deleted (BOOLEAN) -- Logical delete flag
created_at (TIMESTAMP)
updated_at (TIMESTAMP)
```

**NOTA**: PostgreSQL solo almacena metadata estructural:
- **network_snapshot**: InformaciÃ³n de snapshots (denormalizada de Parquet/FS)
- **network, source, harvesting_config**: Datos relacionales
- **NO contiene**: CatÃ¡logo OAI (estÃ¡ en Parquet), Metadata XML (estÃ¡ en FS), ValidaciÃ³n stats (estÃ¡ en JSON)

Ver secciÃ³n de ValidaciÃ³n arriba para detalles de almacenamiento en Filesystem.

---

## ğŸ”’ Thread Safety

### âœ… SEGURO
```java
// Cada thread obtiene NUEVA instancia
Iterator<OAIRecord> it1 = repository.getIterator(metadata);  // Thread 1
Iterator<OAIRecord> it2 = repository.getIterator(metadata);  // Thread 2
// âœ… Sin interferencia
```

### âŒ INSEGURO
```java
// Compartir iterator entre threads
Iterator<OAIRecord> shared = repository.getIterator(metadata);
Thread1: shared.hasNext(); // âš ï¸ Race condition
Thread2: shared.hasNext(); // âš ï¸ Race condition
```

### MÃ©todos Sincronizados
```java
// PostgreSQL - Contadores de snapshot (synchronized)
snapshotStore.incrementSnapshotSize(snapshotId);        // synchronized
snapshotStore.incrementValidSize(snapshotId);           // synchronized

// Logs (synchronized)
snapshotLogService.addEntry(snapshotId, message);       // synchronized

// ValidaciÃ³n - ActualizaciÃ³n de stats en memoria (synchronized)
validationStatRepository.updateStoredStats(...);        // synchronized

// OAIRecord/Validation Writers - Auto sincronizados internamente
oaiRecordManager.writeRecord(record);                   // synchronized interno
validationRecordManager.writeRecord(record);            // synchronized interno
```

---

## ğŸ“ API Quick Reference

### ISnapshotStore
```java
// Lifecycle
Long createSnapshot(Network network)
void saveSnapshot(Long snapshotId)
void deleteSnapshot(Long snapshotId)
void cleanSnapshotData(Long snapshotId)

// Metadata
SnapshotMetadata getSnapshotMetadata(Long snapshotId)

// Status
SnapshotStatus getSnapshotStatus(Long snapshotId)
void updateSnapshotStatus(Long snapshotId, SnapshotStatus status)

// Counters (synchronized)
void incrementSnapshotSize(Long snapshotId)
void incrementValidSize(Long snapshotId)
void incrementTransformedSize(Long snapshotId)
void updateSnapshotCounts(Long snapshotId, Integer size, Integer validSize, Integer transformedSize)
```

### OAIRecordParquetRepository
```java
// Write
void initializeSnapshot(SnapshotMetadata snapshotMetadata)
void saveRecord(Long snapshotId, OAIRecord record)
void flush(Long snapshotId)
void finalizeSnapshot(Long snapshotId)

// Read (Thread-safe - NEW instance each call)
Iterator<OAIRecord> getIterator(SnapshotMetadata snapshotMetadata)

// Management
void deleteSnapshot(Long snapshotId)
boolean hasActiveManager(Long snapshotId)
Map<String, Object> getManagerInfo(Long snapshotId)
```

### SnapshotLogService
```java
// Write
void addEntry(Long snapshotId, String message)
void deleteSnapshotLog(Long snapshotId)

// Read
LogQueryResult getLogEntries(Long snapshotId, int page, int size)
```

---

## ğŸš€ Patrones de Uso Comunes

### Pattern 1: Simple Harvesting
```java
Long snapshotId = snapshotStore.createSnapshot(network);
SnapshotMetadata metadata = snapshotStore.getSnapshotMetadata(snapshotId);
oaiRecordRepository.initializeSnapshot(metadata);

for (OAIRecord record : harvestedRecords) {
    oaiRecordRepository.saveRecord(snapshotId, record);
    snapshotStore.incrementSnapshotSize(snapshotId);
}

oaiRecordRepository.finalizeSnapshot(snapshotId);
snapshotStore.updateSnapshotStatus(snapshotId, SnapshotStatus.HARVESTING_FINISHED_VALID);
```

### Pattern 2: Lectura Segura Multi-Thread
```java
SnapshotMetadata metadata = snapshotStore.getSnapshotMetadata(snapshotId);

// MÃºltiples threads
executor.submit(() -> {
    Iterator<OAIRecord> iterator = repository.getIterator(metadata);
    while (iterator.hasNext()) {
        OAIRecord record = iterator.next();
        process(record);
    }
});
```

### Pattern 3: Lectura de Logs Paginada
```java
LogQueryResult result = snapshotLogService.getLogEntries(snapshotId, 0, 10);
for (LogEntry entry : result.getEntries()) {
    System.out.println(entry.getTimestamp() + " " + entry.getMessage());
}
System.out.println("Page 1 of " + result.getTotalPages());
```

---

## âš™ï¸ ConfiguraciÃ³n (application.properties)

```properties
# Base path para almacenamiento (Metadata XML + Snapshots Parquet)
store.basepath=/data/lareferencia

# Records OAI - Batching
parquet.catalog.records-per-file=10000

# ValidaciÃ³n - Batching (records con RuleFacts anidados)
parquet.validation.records-per-file=10000

# ValidaciÃ³n - Detalle de occurrences dentro de facts (costoso en espacio)
validation.detailed.diagnose=false

# Parquet - CompresiÃ³n
parquet.compression=SNAPPY

# Parquet - Page size (1 MB = 1048576)
parquet.page.size=1048576

# Parquet - Dictionary encoding
parquet.enable.dictionary=true

# Database - PostgreSQL (solo para metadata estructural)
spring.datasource.url=jdbc:postgresql://localhost:5432/lareferencia
spring.datasource.username=postgres
spring.datasource.password=password
```

---

## ğŸ“ˆ Estimaciones de Almacenamiento

**Por 25,000 records** (ver tabla detallada en secciÃ³n "TamaÃ±os Estimados" arriba):
- **Metadata XML**: ~10-12 MB (deduplicaciÃ³n entre snapshots)
- **Snapshot Metadata JSON**: ~2 KB
- **Parquet OAI Records**: ~20 MB (catalog/)
- **Validation Stats JSON**: ~5 KB
- **Validation Index**: ~900 KB (Ã­ndice ligero)
- **Parquet Validation Records**: ~12.5 MB (con RuleFacts anidados)
- **Logs**: ~250 KB
- **PostgreSQL**: ~1-2 MB (metadata estructural)
- **TOTAL**: ~45-48 MB por snapshot completo

**Proyecciones**:
- 100 snapshots = ~4.7 GB
- 1,000 snapshots = ~47 GB
- 10,000 snapshots = ~470 GB

**Ventajas de la Nueva Arquitectura**:
- âœ… ReducciÃ³n ~88% vs fact table tradicional
- âœ… DeduplicaciÃ³n de metadata XML ahorra 30-50%
- âœ… Sin bases de datos complejas para validaciÃ³n
- âœ… RuleFacts anidados en mismo archivo = mejor compresiÃ³n
- âœ… Escalable a millones de records

---

## ğŸ” Monitoreo y Debug

### Ver logs de un snapshot
```bash
curl "http://localhost:8080/rest/log/search/findBySnapshotId?snapshot_id=123&page=0&size=20"
```

### Ver informaciÃ³n de manager activo
```java
if (repository.hasActiveManager(snapshotId)) {
    Map<String, Object> info = repository.getManagerInfo(snapshotId);
    System.out.println("Records: " + info.get("recordsWritten"));
    System.out.println("Batches: " + info.get("batchCount"));
}
```

### Ver metadata de snapshot
```java
SnapshotMetadata metadata = snapshotStore.getSnapshotMetadata(snapshotId);
System.out.println("Size: " + metadata.getSize());
System.out.println("Valid: " + metadata.getValidSize());
System.out.println("Status: " + snapshotStore.getSnapshotStatus(snapshotId));
```

### Ver estadÃ­sticas de validaciÃ³n
```java
// Leer desde JSON (ultra-rÃ¡pido <1ms)
SnapshotValidationStats stats = validationStatRepository.getSnapshotValidationStats(metadata);

System.out.println("Total Records: " + stats.getTotalRecords());
System.out.println("Valid Records: " + stats.getValidRecords());
System.out.println("Invalid Records: " + stats.getInvalidRecords());
System.out.println("Transformed: " + stats.getTransformedRecords());

// Ver stats por regla
RuleStats rule5 = stats.getRuleStats(5L);
System.out.println("Rule 5 - Valid: " + rule5.getValidCount());
System.out.println("Rule 5 - Invalid: " + rule5.getInvalidCount());

// Ver facets
Map<String, Long> validFacet = stats.getFacet("record_is_valid");
System.out.println("Valid: " + validFacet.get("true"));
System.out.println("Invalid: " + validFacet.get("false"));
```

### Consultar occurrences de una regla
```java
// Obtener occurrences detalladas de regla #5
Map<String, Map<String, Integer>> occurrences = 
    validationStatRepository.calculateRuleOccurrences(snapshotId, 5, null);

Map<String, Integer> validOccurrences = occurrences.get("valid");
Map<String, Integer> invalidOccurrences = occurrences.get("invalid");

System.out.println("Valid occurrences:");
validOccurrences.forEach((value, count) -> 
    System.out.println("  " + value + ": " + count)
);
```

---

## âš ï¸ Posibles Problemas

### Problema: Metadata No Encontrada
**SÃ­ntoma**: `MetadataRecordStoreException: Metadata not found for hash`
**Causa**: 
- Archivo XML comprimido fue eliminado del FS
- Hash incorrecto en BD
- ParticiÃ³n equivocada

**SoluciÃ³n**:
```bash
# Verificar si existe el archivo
ls -la /data/metadata/NETWORK/metadata/A/B/C/ABCDEF123456789.xml.gz

# Recalcular hash
String newHash = metadataStore.storeAndReturnHash(snapshot, xmlContent);

# Actualizar referencia en BD
UPDATE oai_record SET metadata_hash = 'newHash' WHERE id = ?
```

### Problema: Disco Lleno (Metadata)
**SÃ­ntoma**: IOException durante storeAndReturnHash
**Causa**: ParticiÃ³n del FS sin espacio
**SoluciÃ³n**:
```bash
# Ver uso
df -h /data/metadata

# Comprimir archivos antiguos (si aplica)
find /data/metadata -mtime +30 -name "*.xml.gz" -exec gzip -9 {} \;

# O borrar snapshots antiguos
snapshotStore.deleteSnapshot(oldSnapshotId);
```

### Problema: Hash Duplicado Incorrecto
**SÃ­ntoma**: Dos records diferentes con mismo hash
**Causa**: 
- Datos corruptos
- ColisiÃ³n (muy raro con SHA-256)

**SoluciÃ³n**:
```java
// Recalcular y verificar
String xml1 = metadataStore.getMetadata(snap, hash);
String xml2 = metadataStore.getMetadata(snap, hash);

if (!xml1.equals(xml2)) {
    logger.error("Hash collision detected!");
    // Regenerar uno de los hashes
}
```

### Problema: Memory Leak en Lectura
**SÃ­ntoma**: Memoria RAM crece leyendo metadata
**Causa**: Buffer no liberado, String muy grande
**SoluciÃ³n**:
```java
// âœ… BUENO - Stream pequeÃ±os chunks
try (InputStream is = new FileInputStream(file);
     GZIPInputStream gzis = new GZIPInputStream(is)) {
    byte[] buffer = new byte[8192];
    int bytesRead;
    while ((bytesRead = gzis.read(buffer)) > 0) {
        process(buffer, bytesRead);
    }
}

// âŒ MALO - Carga todo a memoria
String xml = readCompressed(file); // Si es muy grande
```

---

## ğŸ“š Documentos Relacionados

- `docs/ALMACENAMIENTO_DATOS.md` - DocumentaciÃ³n completa
- `docs/ALMACENAMIENTO_EJEMPLOS.md` - Ejemplos de cÃ³digo
- `docs/PACKAGE_MIGRATION_GUIDE.md` - GuÃ­a de paquetes

---

**Ãšltima actualizaciÃ³n**: 12 de noviembre de 2025
