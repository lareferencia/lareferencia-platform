# AnÃ¡lisis del Modelo de Procesamiento de IndexaciÃ³n Multithreading - Elasticsearch

## ğŸ“‹ Resumen Ejecutivo

El sistema de indexaciÃ³n de LA Referencia para **Elasticsearch** implementa un **modelo de procesamiento multithreading altamente sofisticado** con arquitectura **Producer-Consumer** optimizada especÃ­ficamente para aprovechar las capacidades de indexaciÃ³n concurrente de Elasticsearch.

**Veredicto:** âœ… **SÃ es multithreading** - implementaciÃ³n profesional optimizada para Elasticsearch con control de concurrencia avanzado.

**Nota:** Este anÃ¡lisis se enfoca exclusivamente en la implementaciÃ³n de Elasticsearch. Se omiten las implementaciones de TDB1/TDB2 para RDF.

---

## ğŸ—ï¸ Arquitectura Elasticsearch - Producer-Consumer con MÃºltiples Writers

### Diagrama de Flujo Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAPA DE PRODUCCIÃ“N (Indexing Threads)                                    â”‚
â”‚                                                                           â”‚
â”‚  Thread 1 â”€â”€â”                                                            â”‚
â”‚  Thread 2 â”€â”€â”¤                                                            â”‚
â”‚  Thread 3 â”€â”€â”¼â”€â”€> ExecutorService (CPU cores threads)                     â”‚
â”‚  Thread N â”€â”€â”˜      â”‚                                                     â”‚
â”‚                    â”‚                                                     â”‚
â”‚                    â–¼                                                     â”‚
â”‚              [Semaphore]  â† Control: maxConcurrentTasks (2x cores)       â”‚
â”‚                    â”‚                                                     â”‚
â”‚                    â–¼                                                     â”‚
â”‚         BlockingQueue (documentBuffer)  â† 10,000 documentos              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAPA DE DISTRIBUCIÃ“N (Single Thread)                                     â”‚
â”‚                                                                           â”‚
â”‚          Distributor Thread (Round-Robin)                                â”‚
â”‚                 â”‚                                                        â”‚
â”‚                 â”œâ”€â”€> OutputQueue 1 (Elastic Writer 1)                    â”‚
â”‚                 â”œâ”€â”€> OutputQueue 2 (Elastic Writer 2)                    â”‚
â”‚                 â”œâ”€â”€> OutputQueue 3 (Elastic Writer 3)                    â”‚
â”‚                 â”œâ”€â”€> OutputQueue 4 (Elastic Writer 4)                    â”‚
â”‚                 â”œâ”€â”€> OutputQueue 5 (Elastic Writer 5)                    â”‚
â”‚                 â””â”€â”€> OutputQueue 6 (Elastic Writer 6)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAPA DE ESCRITURA (Elasticsearch Writers - 2 a 6 threads concurrentes)   â”‚
â”‚                                                                           â”‚
â”‚  Elastic Writer Thread 1  â”€â”€â”                                            â”‚
â”‚  Elastic Writer Thread 2  â”€â”€â”¤                                            â”‚
â”‚  Elastic Writer Thread 3  â”€â”€â”¼â”€â”€> Elasticsearch Bulk API                  â”‚
â”‚  Elastic Writer Thread 4  â”€â”€â”¤     (Concurrent Indexing)                  â”‚
â”‚  Elastic Writer Thread 5  â”€â”€â”¤                                            â”‚
â”‚  Elastic Writer Thread 6  â”€â”€â”˜                                            â”‚
â”‚                                                                           â”‚
â”‚  Cada writer:                                                            â”‚
â”‚  - Acumula documentos en batch                                           â”‚
â”‚  - Bulk request cada N documentos o timeout                              â”‚
â”‚  - Retry con backoff exponencial                                         â”‚
â”‚  - Manejo de errores granular                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
              Elasticsearch Cluster
```

### CaracterÃ­sticas Clave de la Arquitectura

**1. Producers (Indexing Threads):**
- NÃºmero de threads = CPU cores disponibles
- Cada thread carga una entidad completa de BD
- TransacciÃ³n independiente por entidad (REQUIRES_NEW)
- Preload de relaciones para evitar lazy loading

**2. Distributor (Thread Ãšnico):**
- Consume del buffer principal (documentBuffer)
- Distribuye documentos round-robin entre writers
- Balance de carga automÃ¡tico
- Maneja markers de flush y shutdown

**3. Elasticsearch Writers (2-6 Threads):**
- **CÃ¡lculo automÃ¡tico:** `Math.max(2, Math.min(indexingThreads, 6))`
- **Configurable:** `elastic.indexer.writer.threads` en properties
- Escritura concurrente aprovechando capacidad de Elasticsearch
- Bulk API para reducir overhead de red
- Cada writer es independiente con su propia conexiÃ³n

---

## ğŸ” JSONElasticEntityIndexerThreadedImpl - ImplementaciÃ³n Detallada

### ConfiguraciÃ³n de Threading

**ExecutorServices:**
```java
private ExecutorService indexingExecutor;  // Pool de threads para indexaciÃ³n
private ExecutorService utilityExecutor;   // Thread Ãºnico para monitoreo
```

**ParÃ¡metros de ConfiguraciÃ³n:**
```java
private int indexingThreads = Runtime.getRuntime().availableProcessors();
private int bufferSize = 10000;
private int maxConcurrentTasks = indexingThreads * 2;
private int elasticWriterThreads = Math.max(2, Math.min(indexingThreads, 6));
```

**CÃ¡lculo AutomÃ¡tico de Writers:**
- **MÃ­nimo:** 2 writers (garantiza concurrencia bÃ¡sica)
- **MÃ¡ximo:** 6 writers (Ã³ptimo para clusters Elasticsearch)
- **Auto-ajuste:** Basado en CPU cores disponibles
- **Override:** Configurable vÃ­a `elastic.indexer.writer.threads` en properties

### Componentes de SincronizaciÃ³n

**1. Semaphore (Control de Backpressure):**
```java
private Semaphore concurrentTasksSemaphore = new Semaphore(maxConcurrentTasks);
```
- **PropÃ³sito:** Limitar tareas de indexaciÃ³n concurrentes
- **LÃ­mite:** 2x nÃºmero de CPU cores
- **Efecto:** Evita saturaciÃ³n de memoria y BD

**2. Phaser (SincronizaciÃ³n de Fases):**
```java
private final Phaser activeIndexingPhaser = new Phaser(1);
```
- **PropÃ³sito:** Rastrear productores activos
- **Uso:** Sincronizar operaciÃ³n flush
- **Mecanismo:** Register/arriveAndDeregister por tarea

**3. BlockingQueues (ComunicaciÃ³n Thread-Safe):**
```java
private BlockingQueue<Object> documentBuffer = new LinkedBlockingQueue<>(10000);
private final List<BlockingQueue<Object>> outputQueues = new ArrayList<>();
```
- **Buffer principal:** 10,000 documentos JSON
- **Output queues:** Una por cada Elasticsearch writer
- **Thread-safe:** No requiere sincronizaciÃ³n externa

---

## âš™ï¸ Flujo de Procesamiento Completo

### Fase 1: ProducciÃ³n de Documentos (Indexing Threads)

**MÃ©todo Principal `index(Entity)`:**
```java
@Override
public void index(Entity entity) throws EntityIndexingException {
    // 1. Adquirir permiso del semÃ¡foro (BLOCKING si no hay slots)
    concurrentTasksSemaphore.acquire();
    
    // 2. Registrar en phaser
    activeIndexingPhaser.register();
    
    // 3. Capturar solo el ID (evitar lazy loading)
    final UUID entityId = entity.getId();
    
    // 4. Lanzar procesamiento asÃ­ncrono
    CompletableFuture.runAsync(() -> {
        try {
            processEntityAsync(entityId);
        } finally {
            concurrentTasksSemaphore.release();
            activeIndexingPhaser.arriveAndDeregister();
        }
    }, indexingExecutor);
    
    // 5. Retornar INMEDIATAMENTE (non-blocking)
}
```

**Procesamiento AsÃ­ncrono por Entidad:**
```java
private void processEntityAsync(UUID entityId) {
    // 1. Crear transacciÃ³n INDEPENDIENTE
    DefaultTransactionDefinition def = new DefaultTransactionDefinition();
    def.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRES_NEW);
    def.setIsolationLevel(TransactionDefinition.ISOLATION_READ_COMMITTED);
    TransactionStatus status = transactionManager.getTransaction(def);
    
    try {
        // 2. Recargar entidad desde BD (thread-safe)
        Entity freshEntity = entityDataService.getEntityById(entityId).get();
        
        // 3. Pre-cargar todas las relaciones (evitar lazy loading)
        Entity fullyLoadedEntity = preloadEntityData(freshEntity);
        
        // 4. Generar documento JSON
        JSONEntityElastic jsonDoc = buildJSONDocument(fullyLoadedEntity);
        
        // 5. Enviar a buffer
        documentBuffer.put(jsonDoc);
        documentsProduced.incrementAndGet();
        
        // 6. Commit transacciÃ³n
        transactionManager.commit(status);
        
    } catch (Exception e) {
        transactionManager.rollback(status);
        throw e;
    }
}
```

### Fase 2: DistribuciÃ³n (Distributor Thread)

**Thread Distribuidor (Round-Robin):**
```java
private class Distributor implements Runnable {
    private int currentWriterIndex = 0;
    
    @Override
    public void run() {
        while (!shutdown) {
            try {
                Object item = documentBuffer.take(); // BLOCKING
                
                if (item == POISON_PILL) {
                    // Shutdown signal
                    propagatePoisonPills();
                    break;
                }
                
                if (item instanceof FlushMarker) {
                    // Flush signal
                    propagateFlushMarker((FlushMarker) item);
                    continue;
                }
                
                if (item instanceof JSONEntityElastic) {
                    // Distribuir round-robin
                    BlockingQueue<Object> targetQueue = 
                        outputQueues.get(currentWriterIndex);
                    targetQueue.put(item);
                    currentWriterIndex = (currentWriterIndex + 1) % outputQueues.size();
                    documentsConsumed.incrementAndGet();
                }
                
            } catch (InterruptedException e) {
                break;
            }
        }
    }
}
```

### Fase 3: Escritura a Elasticsearch (Writer Threads)

**Elasticsearch Writer (Bulk Indexing):**
```java
private class ElasticsearchWriter implements Runnable {
    private final BlockingQueue<Object> inputQueue;
    private final RestHighLevelClient client;
    private final List<JSONEntityElastic> batch = new ArrayList<>();
    private static final int BATCH_SIZE = 500;
    private static final long FLUSH_INTERVAL_MS = 5000;
    
    @Override
    public void run() {
        long lastFlushTime = System.currentTimeMillis();
        
        while (!shutdown || !inputQueue.isEmpty()) {
            try {
                Object item = inputQueue.poll(1, TimeUnit.SECONDS);
                
                if (item == POISON_PILL) break;
                
                if (item instanceof FlushMarker) {
                    flushBatch();
                    ((FlushMarker) item).latch.countDown();
                    continue;
                }
                
                if (item instanceof JSONEntityElastic) {
                    batch.add((JSONEntityElastic) item);
                    
                    // Flush si batch lleno o timeout
                    if (batch.size() >= BATCH_SIZE || 
                        System.currentTimeMillis() - lastFlushTime > FLUSH_INTERVAL_MS) {
                        flushBatch();
                        lastFlushTime = System.currentTimeMillis();
                    }
                }
                
            } catch (InterruptedException e) {
                break;
            }
        }
        
        // Flush final
        flushBatch();
    }
    
    private void flushBatch() {
        if (batch.isEmpty()) return;
        
        BulkRequest bulkRequest = new BulkRequest();
        for (JSONEntityElastic doc : batch) {
            IndexRequest indexRequest = new IndexRequest(indexName)
                .id(doc.getId())
                .source(jsonMapper.writeValueAsString(doc), XContentType.JSON);
            bulkRequest.add(indexRequest);
        }
        
        // Retry logic con backoff exponencial
        int retries = 0;
        while (retries < MAX_RETRIES) {
            try {
                BulkResponse response = client.bulk(bulkRequest, RequestOptions.DEFAULT);
                if (!response.hasFailures()) {
                    documentsIndexed.addAndGet(batch.size());
                    batch.clear();
                    break;
                }
                // Manejar failures parciales
                handlePartialFailures(response);
                break;
                
            } catch (IOException e) {
                retries++;
                long backoff = (long) Math.pow(2, retries) * 1000;
                Thread.sleep(Math.min(backoff, 30000));
            }
        }
    }
}
```

---

## ğŸ¯ CaracterÃ­sticas Avanzadas Elasticsearch

### 1. Preload de Datos (Evitar N+1 y Lazy Loading)

```java
private Entity preloadEntityData(Entity entity) {
    // Cargar tipo de entidad
    EntityType type = entityModelCache.getObjectById(
        EntityType.class, entity.getEntityTypeId());
    
    EntityIndexingConfig config = configsByEntityType.get(type.getName());
    
    // Pre-cargar field occurrences si necesario
    List<FieldIndexingConfig> fields = config.getFields();
    if (fields != null && !fields.isEmpty()) {
        entity.loadOcurrences(
            entityModelCache.getNamesByIdMap(FieldType.class));
    }
    
    // Pre-cargar TODAS las relaciones
    for (RelationIndexingConfig relConfig : config.getRelationMappings()) {
        Set<Relation> relations = entityDataService
            .getRelationsWithThisEntityAsMember(
                entity.getId(), 
                relConfig.getName(), 
                relConfig.isFromMember());
        
        // Forzar carga de entidades relacionadas
        for (Relation rel : relations) {
            Entity relatedEntity = rel.getRelatedEntity(entity.getId());
            if (relatedEntity != null) {
                relatedEntity.getId(); // Trigger load
            }
        }
    }
    
    return entity;
}
```

**Beneficios:**
- Elimina lazy loading exceptions en threads paralelos
- Reduce nÃºmero de queries a BD (batch loading)
- Una transacciÃ³n independiente carga TODO lo necesario

### 2. ConstrucciÃ³n de Documento JSON

```java
private JSONEntityElastic buildJSONDocument(Entity entity) {
    JSONEntityElastic doc = new JSONEntityElastic();
    doc.setId(entity.getId().toString());
    
    EntityType type = entityModelCache.getObjectById(
        EntityType.class, entity.getEntityTypeId());
    EntityIndexingConfig config = configsByEntityType.get(type.getName());
    
    // Mapear campos
    for (FieldIndexingConfig fieldConfig : config.getFields()) {
        String fieldName = fieldConfig.getName();
        Collection<FieldOccurrence> occurrences = 
            entity.getFieldOccurrencesByFieldName(fieldName);
        
        if (fieldConfig.isMultivalued()) {
            doc.addField(fieldConfig.getTargetField(), 
                         occurrences.stream()
                             .map(FieldOccurrence::getValue)
                             .collect(Collectors.toList()));
        } else if (!occurrences.isEmpty()) {
            doc.addField(fieldConfig.getTargetField(), 
                         occurrences.iterator().next().getValue());
        }
    }
    
    // Mapear relaciones como nested objects
    for (RelationIndexingConfig relConfig : config.getRelationMappings()) {
        Set<Relation> relations = entityDataService
            .getRelationsWithThisEntityAsMember(...);
        
        List<Map<String, Object>> nestedDocs = new ArrayList<>();
        for (Relation rel : relations) {
            Map<String, Object> nestedDoc = new HashMap<>();
            Entity relatedEntity = rel.getRelatedEntity(entity.getId());
            
            // Agregar campos de la entidad relacionada
            nestedDoc.put("id", relatedEntity.getId().toString());
            nestedDoc.put("type", relatedEntity.getEntityType().getName());
            
            // Agregar campos de la relaciÃ³n
            for (FieldIndexingConfig relField : relConfig.getFields()) {
                // ... mapear campos
            }
            
            nestedDocs.add(nestedDoc);
        }
        
        doc.addField(relConfig.getTargetField(), nestedDocs);
    }
    
    return doc;
}
```

### 3. Bulk Indexing Optimization

**Estrategia de Batching:**
- **TamaÃ±o de batch:** 500 documentos (configurable)
- **Timeout:** 5 segundos (flush automÃ¡tico)
- **Triggers:** Batch lleno O timeout alcanzado

**Ventajas:**
- Reduce nÃºmero de requests HTTP a Elasticsearch
- Aprovecha bulk API para mejor throughput
- Balancea latencia vs throughput

### 4. Retry Logic con Backoff Exponencial

```java
int retries = 0;
while (retries < MAX_RETRIES) {
    try {
        BulkResponse response = client.bulk(bulkRequest, RequestOptions.DEFAULT);
        if (!response.hasFailures()) {
            break; // Success
        }
        handlePartialFailures(response);
        break;
    } catch (IOException e) {
        retries++;
        long backoff = (long) Math.pow(2, retries) * 1000; // Exponencial
        Thread.sleep(Math.min(backoff, 30000)); // Max 30s
    }
}
```

**Backoff:**
- Retry 1: 2 segundos
- Retry 2: 4 segundos
- Retry 3: 8 segundos
- ...
- Retry 10: 30 segundos (cap)

---

---

## ğŸ“Š Mecanismos de Control de Concurrencia en Elasticsearch

### 1. Semaphore - Backpressure Control

**ConfiguraciÃ³n:**
```java
private Semaphore concurrentTasksSemaphore = new Semaphore(maxConcurrentTasks);
// maxConcurrentTasks = indexingThreads * 2
```

**Comportamiento:**
- Limita el nÃºmero de tareas de indexaciÃ³n concurrentes ejecutÃ¡ndose simultÃ¡neamente
- Si no hay permisos disponibles, `acquire()` bloquea el thread hasta que se libere uno
- Evita saturaciÃ³n de base de datos PostgreSQL y memoria JVM
- Ejemplo con 8 cores: permite max 16 tareas concurrentes

**Flujo de EjecuciÃ³n:**
```
Thread 1 â†’ acquire() âœ“ (permit 1/16) â†’ load entity â†’ create JSON â†’ release()
Thread 2 â†’ acquire() âœ“ (permit 2/16) â†’ load entity â†’ create JSON â†’ release()
...
Thread 17 â†’ acquire() â¸ BLOCKED (no permits) â†’ esperando...
Thread 1 â†’ release() â†’ Thread 17 unblocked âœ“ â†’ continÃºa
```

**Beneficio en PostgreSQL:**
- Previene connection pool exhaustion
- Evita timeouts por saturaciÃ³n de transacciones concurrentes
- Controla memoria usada por entidades cargadas en paralelo

### 2. Phaser - SincronizaciÃ³n de Fases

**PropÃ³sito:**
- Rastrear cuÃ¡ntos productores (indexing threads) estÃ¡n activos
- Sincronizar operaciÃ³n `flush()` para garantizar que todos los documentos se procesen

**Operaciones Clave:**
```java
// Al iniciar indexaciÃ³n de una entidad
activeIndexingPhaser.register();  // Incrementa contador de tareas activas

// Al terminar procesamiento
activeIndexingPhaser.arriveAndDeregister();  // Decrementa contador

// En flush() - esperar a que TODOS los producers terminen
activeIndexingPhaser.arriveAndAwaitAdvance();
```

**Flujo de Flush:**
```
1. User llama indexer.flush()
2. Phaser espera: 5 tareas activas â†’ espera...
3. Tarea 1 termina â†’ 4 activas â†’ espera...
4. Tarea 2 termina â†’ 3 activas â†’ espera...
5. Tarea 5 termina â†’ 0 activas â†’ CONTINÃšA
6. EnvÃ­a FlushMarker a writers
7. Espera confirmaciÃ³n de todos los writers
8. Retorna (flush completo)
```

### 3. BlockingQueue - ComunicaciÃ³n Thread-Safe

**Colas Utilizadas:**
```java
private BlockingQueue<Object> documentBuffer = new LinkedBlockingQueue<>(10000);
private List<BlockingQueue<Object>> outputQueues; // Una por cada Elasticsearch writer (2-6)
```

**Ventajas del Modelo Producer-Consumer:**
- **Thread-safe automÃ¡tico:** No requiere `synchronized` manual
- **Blocking operations:** `put()` bloquea si cola llena, `take()` bloquea si vacÃ­a
- **Desacoplamiento:** Productores y consumidores operan a velocidades independientes
- **Buffer intermedio:** Absorbe picos de velocidad entre BD y Elasticsearch

**Ejemplo de Flujo:**
```
Producer Thread 1 â†’ documentBuffer.put(doc1) â†’ Buffer: [doc1]
Producer Thread 2 â†’ documentBuffer.put(doc2) â†’ Buffer: [doc1, doc2]
Distributor Thread â†’ documentBuffer.take() â†’ obtiene doc1 â†’ Buffer: [doc2]
Distributor â†’ outputQueues[0].put(doc1) â†’ Writer 0 recibe doc1
Distributor â†’ documentBuffer.take() â†’ obtiene doc2 â†’ Buffer: []
Distributor â†’ outputQueues[1].put(doc2) â†’ Writer 1 recibe doc2
```

**Capacidad y Comportamiento:**
- **Buffer principal:** 10,000 documentos JSON
- **Output queues:** Ilimitadas (LinkedBlockingQueue sin capacidad)
- **Backpressure:** Si buffer lleno, producers bloquean en `put()`

---

## ğŸ“Š MÃ©tricas y Monitoreo

### Contadores AtÃ³micos (Thread-Safe)

```java
private final AtomicLong documentsProduced = new AtomicLong(0);
private final AtomicLong documentsConsumed = new AtomicLong(0);
private final AtomicLong documentsIndexed = new AtomicLong(0);
```

**Â¿Por quÃ© AtomicLong?**
- Operaciones thread-safe sin `synchronized`
- MÃ©todo `incrementAndGet()` es atÃ³mico
- Mejor performance que sincronizaciÃ³n explÃ­cita
- Lectura consistente desde mÃºltiples threads

### EstadÃ­sticas Reportadas

**Elasticsearch Indexing Stats:**
- **Documentos producidos:** Total de documentos JSON creados
- **Documentos consumidos:** Total procesados por distributor
- **Documentos indexados:** Total enviados a Elasticsearch (confirmados)
- **Buffer usage:** `documentBuffer.size() / 10000 * 100%`
- **Active tasks:** Tareas de indexaciÃ³n en progreso
- **Memory usage:** Heap JVM utilizado/disponible
- **Bulk operations:** NÃºmero de bulk requests enviados
- **Bulk failures:** Documentos que fallaron en indexaciÃ³n

### Logging de Progreso

```java
logger.info("[ELASTIC INDEXING STATUS] " +
    "Buffer: {}/{} ({}%). " +
    "Active Tasks: {}. " +
    "Slots: {}/{}. " +
    "Docs: Produced:{}, Consumed:{}, Indexed:{} ({}%). " +
    "Bulk Ops: {} (Failures: {}). " +
    "Memory: {}MB/{}MB",
    bufferSize, bufferCapacity, bufferPercentage,
    activeTasks,
    availableSlots, maxSlots,
    produced, consumed, indexed, indexedPercentage,
    bulkOps, bulkFailures,
    usedMemory, maxMemory);
```

---

## âš¡ Optimizaciones de Performance

### 1. Transacciones Independientes (REQUIRES_NEW)

**ConfiguraciÃ³n:**
```java
DefaultTransactionDefinition def = new DefaultTransactionDefinition();
def.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRES_NEW);
def.setIsolationLevel(TransactionDefinition.ISOLATION_READ_COMMITTED);
def.setTimeout(300); // 5 minutos
```

**Ventajas:**
- Cada thread tiene su propia transacciÃ³n PostgreSQL
- No hay bloqueos entre threads
- Rollback de un thread no afecta otros
- Permite verdadero procesamiento paralelo

### 2. Preload de Relaciones

**Estrategia:**
- Cargar TODAS las relaciones en la transacciÃ³n inicial
- Evitar lazy loading en procesamiento posterior
- Trigger de Hibernate para forzar carga

**Resultado:**
- Elimina N+1 queries
- Una transacciÃ³n carga todo lo necesario
- No hay acceso a BD en fase de construcciÃ³n de JSON

### 3. Bulk API de Elasticsearch

**Ventajas:**
```
OperaciÃ³n individual: 500 docs Ã— 1 request/doc = 500 HTTP requests
Bulk API:           500 docs Ã— 1 bulk request = 1 HTTP request
ReducciÃ³n:          99.8% menos overhead de red
```

**ConfiguraciÃ³n Ã“ptima:**
- Batch size: 500 documentos
- Timeout: 5 segundos
- Flush si batch lleno O timeout alcanzado

### 4. MÃºltiples Elasticsearch Writers (2-6)

**CÃ¡lculo AutomÃ¡tico:**
```java
int writers = Math.max(2, Math.min(indexingThreads, 6));
```

**Ejemplo con diferentes CPUs:**
- **2 cores:** 2 writers (mÃ­nimo garantizado)
- **4 cores:** 4 writers
- **8 cores:** 6 writers (cap mÃ¡ximo)
- **16 cores:** 6 writers (cap mÃ¡ximo)

**Â¿Por quÃ© cap en 6?**
- Elasticsearch cluster tÃ­pico: 3-5 nodos
- MÃ¡s de 6 conexiones concurrentes no mejora throughput
- Evita saturaciÃ³n de conexiones HTTP
- Balance Ã³ptimo entre concurrencia y overhead

---

activeIndexingPhaser.arriveAndAwaitAdvance(); // Esperar todos
```

---

## ğŸš¨ Manejo de Errores en Elasticsearch Indexing

### 1. Producers (Indexing Threads)

**Estrategia: Isolate Failures**
```java
try {
    // Procesar entidad con transacciÃ³n independiente
    Entity fullyLoadedEntity = preloadEntityData(freshEntity);
    JSONEntityElastic jsonDoc = buildJSONDocument(fullyLoadedEntity);
    documentBuffer.put(jsonDoc);
    transactionManager.commit(status);
    
} catch (Exception e) {
    transactionManager.rollback(status);
    logger.error("Error processing entity {}: {}", entityId, e.getMessage(), e);
    // NO propaga - failure de una entidad NO detiene otras
    
} finally {
    // SIEMPRE liberar recursos
    concurrentTasksSemaphore.release();
    activeIndexingPhaser.arriveAndDeregister();
}
```

**Beneficios:**
- Error en entity X no afecta entity Y
- Transacciones independientes permiten rollback aislado
- Semaphore y Phaser se liberan correctamente
- Log detallado para debugging

### 2. Distributor Thread

**Estrategia: Resilient Distribution**
```java
try {
    Object item = documentBuffer.take(); // BLOCKING
    
    if (item == POISON_PILL) {
        propagatePoisonPills(); // Shutdown graceful
        break;
    }
    
    if (item instanceof FlushMarker) {
        propagateFlushMarker((FlushMarker) item);
        continue;
    }
    
    // Distribuir round-robin
    BlockingQueue<Object> targetQueue = outputQueues.get(currentWriterIndex);
    targetQueue.put(item);
    
} catch (InterruptedException e) {
    logger.warn("Distributor interrupted", e);
    Thread.currentThread().interrupt();
    break;
    
} catch (Exception e) {
    logger.error("Unexpected error in distributor", e);
    // ContinÃºa procesando - no detiene pipeline
}
```

### 3. Elasticsearch Writers

**Estrategia: Retry con Backoff Exponencial**
```java
private void flushBatch() {
    if (batch.isEmpty()) return;
    
    BulkRequest bulkRequest = buildBulkRequest(batch);
    int retries = 0;
    
    while (retries < MAX_RETRIES) {
        try {
            BulkResponse response = client.bulk(bulkRequest, RequestOptions.DEFAULT);
            
            if (!response.hasFailures()) {
                // SUCCESS
                documentsIndexed.addAndGet(batch.size());
                batch.clear();
                return;
            }
            
            // Partial failures
            handlePartialFailures(response);
            return;
            
        } catch (IOException e) {
            retries++;
            logger.warn("Bulk indexing failed (attempt {}/{}): {}", 
                       retries, MAX_RETRIES, e.getMessage());
            
            if (retries >= MAX_RETRIES) {
                logger.error("Max retries reached. {} documents lost", batch.size());
                batch.clear(); // Evitar loop infinito
                return;
            }
            
            // Backoff exponencial: 2^retries segundos (max 30s)
            long backoffMs = (long) Math.pow(2, retries) * 1000;
            long sleepTime = Math.min(backoffMs, 30000);
            
            try {
                Thread.sleep(sleepTime);
            } catch (InterruptedException ie) {
                Thread.currentThread().interrupt();
                return;
            }
        }
    }
}

private void handlePartialFailures(BulkResponse response) {
    List<JSONEntityElastic> failedDocs = new ArrayList<>();
    
    for (BulkItemResponse itemResponse : response.getItems()) {
        if (itemResponse.isFailed()) {
            BulkItemResponse.Failure failure = itemResponse.getFailure();
            logger.error("Document {} failed: {}", 
                        itemResponse.getId(), 
                        failure.getMessage());
            
            // Guardar para retry selectivo
            failedDocs.add(batch.get(itemResponse.getItemId()));
        }
    }
    
    // Actualizar contadores
    int successful = batch.size() - failedDocs.size();
    documentsIndexed.addAndGet(successful);
    
    // Retry solo los que fallaron
    batch.clear();
    batch.addAll(failedDocs);
}
```

**Backoff Progresivo:**
- Retry 1: 2 segundos
- Retry 2: 4 segundos
- Retry 3: 8 segundos
- Retry 4: 16 segundos
- Retry 5+: 30 segundos (cap)

### 4. Graceful Shutdown

```java
@Override
public void close() {
    logger.info("Initiating graceful shutdown...");
    shutdown = true;
    
    // 1. Detener aceptaciÃ³n de nuevas tareas
    indexingExecutor.shutdown();
    
    // 2. Esperar a que producers terminen
    try {
        if (!indexingExecutor.awaitTermination(60, TimeUnit.SECONDS)) {
            logger.warn("Indexing executor did not terminate in time. Forcing shutdown...");
            indexingExecutor.shutdownNow();
        }
    } catch (InterruptedException e) {
        indexingExecutor.shutdownNow();
        Thread.currentThread().interrupt();
    }
    
    // 3. Enviar POISON_PILL para terminar pipeline
    try {
        documentBuffer.put(POISON_PILL);
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
    }
    
    // 4. Esperar distributor y writers
    if (distributorThread != null) {
        distributorThread.join(30000); // 30 segundos timeout
    }
    
    for (Thread writerThread : writerThreads) {
        writerThread.join(30000);
    }
    
    // 5. Cerrar cliente Elasticsearch
    try {
        elasticClient.close();
    } catch (IOException e) {
        logger.error("Error closing Elasticsearch client", e);
    }
    
    logger.info("Shutdown complete. Final stats: " +
                "Produced:{}, Indexed:{}", 
                documentsProduced.get(), 
                documentsIndexed.get());
}
```

---

## ğŸ“ˆ Escalabilidad y Tunning

### ConfiguraciÃ³n Auto-Ajustable

**DetecciÃ³n AutomÃ¡tica de Recursos:**
```java
// Threads de indexaciÃ³n = CPU cores disponibles
int indexingThreads = Runtime.getRuntime().availableProcessors();

// Max tareas concurrentes = 2x threads (backpressure control)
int maxConcurrentTasks = indexingThreads * 2;

// Elasticsearch writers = 2-6 (Ã³ptimo para clusters tÃ­picos)
int elasticWriterThreads = Math.max(2, Math.min(indexingThreads, 6));
```

**Override Manual (application.properties):**
```properties
# Indexing threads (default: auto)
indexer.threads=16

# Elasticsearch writers (default: auto 2-6)
elastic.indexer.writer.threads=4

# Buffer size (default: 10000)
indexer.buffer.size=20000

# Bulk batch size (default: 500)
elastic.bulk.batch.size=1000

# Bulk flush interval ms (default: 5000)
elastic.bulk.flush.interval=3000
```

### AdaptaciÃ³n por Workload

**MÃ¡quinas PequeÃ±as (4 cores):**
```
Indexing Threads:      4
Max Concurrent Tasks:  8
Document Buffer:       10,000
Elasticsearch Writers: 2 (mÃ­nimo)
Bulk Batch Size:       500
Throughput Estimado:   ~500-1000 docs/seg
```

**MÃ¡quinas Medianas (8 cores):**
```
Indexing Threads:      8
Max Concurrent Tasks:  16
Document Buffer:       10,000
Elasticsearch Writers: 6 (Ã³ptimo)
Bulk Batch Size:       500
Throughput Estimado:   ~2000-4000 docs/seg
```

**MÃ¡quinas Grandes (32 cores):**
```
Indexing Threads:      32
Max Concurrent Tasks:  64
Document Buffer:       20,000 (ajustado)
Elasticsearch Writers: 6 (cap)
Bulk Batch Size:       1000 (ajustado)
Throughput Estimado:   ~8000-15000 docs/seg
```

### Tunning por Bottleneck

**Bottleneck: PostgreSQL (Connection Pool)**
```properties
# Aumentar connection pool
spring.datasource.hikari.maximum-pool-size=40

# Reducir concurrent tasks para no saturar BD
indexer.max.concurrent.tasks=20
```

**Bottleneck: Elasticsearch (Network/Cluster)**
```properties
# Aumentar bulk batch size (menos requests)
elastic.bulk.batch.size=1000

# Aumentar writers si cluster es grande
elastic.indexer.writer.threads=8

# Ajustar timeout de bulk requests
elastic.bulk.timeout.seconds=60
```

**Bottleneck: Memoria JVM**
```properties
# Reducir buffer size
indexer.buffer.size=5000

# Reducir concurrent tasks
indexer.max.concurrent.tasks=10

# Flush mÃ¡s frecuente
elastic.bulk.flush.interval=2000
```

**Bottleneck: CPU**
```properties
# Reducir indexing threads
indexer.threads=4

# Reducir concurrent tasks
indexer.max.concurrent.tasks=8
```

---
- 32 indexing threads
- 64 concurrent tasks max
- 6 Elasticsearch writers

### ConfiguraciÃ³n Externa

```properties
# application.properties
elastic.indexer.writer.threads=4  # Override auto-calculation
```

---

## ğŸ¯ Conclusiones

### âœ… Fortalezas de la Arquitectura Elasticsearch

1. **Arquitectura Robusta y Eficiente:**
   - **Producer-Consumer pattern:** SeparaciÃ³n clara entre carga de BD y escritura a Elasticsearch
   - **Pipeline de 3 capas:** ProducciÃ³n â†’ DistribuciÃ³n â†’ Escritura
   - **Desacoplamiento:** Cada capa opera a su propia velocidad sin bloquear otras
   - **Escalabilidad horizontal:** Auto-ajuste basado en CPU cores disponibles

2. **Control de Concurrencia Sofisticado:**
   - **Semaphore:** Backpressure control para evitar saturaciÃ³n de PostgreSQL
   - **Phaser:** SincronizaciÃ³n de fases para flush garantizado
   - **BlockingQueues:** ComunicaciÃ³n thread-safe sin sincronizaciÃ³n manual
   - **AtomicLong:** Contadores thread-safe de alta performance

3. **Optimizaciones de Performance:**
   - **Preload de relaciones:** Elimina N+1 queries, una transacciÃ³n carga TODO
   - **Transacciones independientes (REQUIRES_NEW):** No hay bloqueos entre threads, rollback aislado
   - **Bulk API de Elasticsearch:** 99.8% reducciÃ³n de overhead de red (500 docs en 1 request)
   - **Round-robin distribution:** DistribuciÃ³n balanceada entre 2-6 Elasticsearch writers

4. **Observabilidad y Monitoreo:**
   - **Logging detallado:** Estado de buffers, tasks activas, throughput, memoria
   - **MÃ©tricas atÃ³micas:** Documentos producidos/consumidos/indexados
   - **Bulk operation tracking:** Failures, retries, tiempos de respuesta
   - **Memory monitoring:** Alertas proactivas de uso de heap JVM

5. **Resiliencia y Manejo de Errores:**
   - **Isolation de fallos:** Error en entity X no afecta entity Y
   - **Retry con backoff exponencial:** Hasta 10 reintentos con delays progresivos
   - **Partial failure handling:** Reintenta solo los documentos que fallaron en bulk
   - **Graceful shutdown:** Cierre ordenado con flush completo de buffers

6. **Elasticidad y Auto-Tunning:**
   - **Auto-detecciÃ³n de recursos:** Threads = CPU cores, writers = 2-6 automÃ¡tico
   - **ConfiguraciÃ³n externa:** Override via application.properties
   - **AdaptaciÃ³n por workload:** 500-15000 docs/seg segÃºn hardware
   - **MÃºltiples puntos de tunning:** Buffer size, bulk batch, flush interval, etc.

### âš ï¸ Consideraciones de ImplementaciÃ³n

1. **Complejidad ArquitectÃ³nica:**
   - CÃ³digo con mÃºltiples niveles de threading y sincronizaciÃ³n
   - Debugging requiere entender Producer-Consumer pattern
   - Curva de aprendizaje moderada-alta para nuevos desarrolladores
   - RecomendaciÃ³n: DocumentaciÃ³n exhaustiva y logging detallado

2. **Consumo de Memoria:**
   - **Preload de entidades:** Puede consumir mucha memoria con entidades grandes/complejas
   - **Buffers en memoria:** documentBuffer (10k), outputQueues (6), cada uno con objetos JSON
   - **Concurrent tasks:** Hasta 2x CPU cores en memoria simultÃ¡neamente
   - **MitigaciÃ³n:** Semaphore limita max concurrent, monitoring de heap JVM

3. **Dependencia de ConfiguraciÃ³n:**
   - **Muchos parÃ¡metros de tunning:** threads, buffer size, bulk size, flush interval, writers, etc.
   - **Valores Ã³ptimos varÃ­an:** Dependen de hardware, tamaÃ±o de entidades, Elasticsearch cluster
   - **Trial and error:** Requiere testing de carga para encontrar valores Ã³ptimos
   - **RecomendaciÃ³n:** Empezar con valores default auto-calculados, ajustar solo si hay bottlenecks

4. **CoordinaciÃ³n con PostgreSQL:**
   - **Connection pool:** Debe configurarse para soportar max concurrent tasks
   - **Lock contention:** Transacciones REQUIRES_NEW reducen pero no eliminan locks
   - **RecomendaciÃ³n:** Hikari pool size â‰¥ max concurrent tasks + 10%

5. **CoordinaciÃ³n con Elasticsearch:**
   - **Cluster size:** Writers Ã³ptimos dependen de nÃºmero de nodos ES
   - **Network bandwidth:** Bulk size grande requiere buena conectividad
   - **Index refresh rate:** Puede causar latencia si es muy bajo
   - **RecomendaciÃ³n:** 2-6 writers es Ã³ptimo para clusters tÃ­picos de 3-5 nodos

### ğŸ“ Recomendaciones para ProducciÃ³n

**1. Monitoreo y Alertas:**
```properties
# Implementar mÃ©tricas Prometheus
management.metrics.export.prometheus.enabled=true

# Alertas recomendadas:
- Buffer usage > 80% (backpressure alto)
- Active tasks near max (saturaciÃ³n)
- Memory usage > 85% (riesgo OOM)
- Bulk failures > 5% (problemas con ES)
- Indexing lag > 10 min (throughput bajo)
```

**2. Testing de Carga:**
```java
// Test scenarios
1. 10,000 entidades simples (1-5 relaciones) â†’ baseline performance
2. 1,000 entidades complejas (50+ relaciones) â†’ memory stress test
3. 100,000 entidades medianas (10-20 relaciones) â†’ throughput test
4. Concurrent indexing + bÃºsquedas â†’ stress test completo
```

**3. ConfiguraciÃ³n Inicial Conservadora:**
```properties
# Empezar conservador, escalar segÃºn necesidad
indexer.threads=auto  # CPU cores
indexer.max.concurrent.tasks=auto  # 2x threads
elastic.indexer.writer.threads=auto  # 2-6
indexer.buffer.size=10000
elastic.bulk.batch.size=500
elastic.bulk.flush.interval=5000
```

**4. Tunning por Bottleneck Observado:**
- **BD lenta:** Aumentar connection pool, reducir concurrent tasks
- **Elasticsearch lento:** Aumentar bulk batch, aumentar writers (si cluster grande)
- **Memoria alta:** Reducir buffer size, reducir concurrent tasks
- **CPU alto:** Reducir indexing threads

### ğŸ“Š IntegraciÃ³n con Flujo de Datos Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 1: CARGA (EntityDataService)                           â”‚
â”‚ - Single threaded                                           â”‚
â”‚ - Una TX por archivo XML                                    â”‚
â”‚ - Inserta en source_entity, source_relation                 â”‚
â”‚ - Marca dirty=true                                          â”‚
â”‚                                                              â”‚
â”‚ Comando: load_data --file=...                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 2: MERGE (SQL Function)                                â”‚
â”‚ - Batch processing (PostgreSQL)                             â”‚
â”‚ - Consolida source_entity â†’ entity                          â”‚
â”‚ - Consolida source_relation â†’ relation                      â”‚
â”‚ - Marca dirty=false                                         â”‚
â”‚                                                              â”‚
â”‚ Comando: merge_dirty_entities                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 3: INDEXACIÃ“N (JSONElasticEntityIndexerThreadedImpl)   â”‚
â”‚ - Multithreaded (CPU cores)                                 â”‚
â”‚ - Transacciones independientes (REQUIRES_NEW)               â”‚
â”‚ - Pipeline Producer-Consumer                                â”‚
â”‚ - Bulk indexing a Elasticsearch                             â”‚
â”‚                                                              â”‚
â”‚ AutomÃ¡tico: Al guardar/actualizar entities                  â”‚
â”‚ Manual: reindex_all                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RESULTADO: Elasticsearch Cluster                            â”‚
â”‚ - Documentos JSON indexados                                 â”‚
â”‚ - BÃºsqueda full-text disponible                             â”‚
â”‚ - Nested objects (relaciones) navegables                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Consistencia ArquitectÃ³nica:**
- **Carga:** Transaccional Ãºnica (MANDATORY), single-threaded, dirty=true
- **Merge:** Batch SQL, consolida fuentes, dirty=false
- **IndexaciÃ³n:** Multithreaded (REQUIRES_NEW), paralelo, Elasticsearch

**Complementariedad:**
- Carga e indexaciÃ³n operan en fases separadas (no hay conflictos)
- Merge intermedio garantiza consolidaciÃ³n antes de indexar
- Cada fase optimizada para su workload especÃ­fico

---

## ğŸ“š Referencias TÃ©cnicas

**Patrones de Concurrencia:**
- Producer-Consumer Pattern: https://en.wikipedia.org/wiki/Producer%E2%80%93consumer_problem
- Pipeline Architecture: https://www.enterpriseintegrationpatterns.com/patterns/messaging/PipesAndFilters.html
- Phaser (Java Concurrency): https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Phaser.html
- Semaphore: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Semaphore.html

**Elasticsearch Best Practices:**
- Bulk API: https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html
- Indexing Performance: https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html
- Java High Level REST Client: https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-high.html

**Spring Framework:**
- Transaction Management: https://docs.spring.io/spring-framework/docs/current/reference/html/data-access.html#transaction
- Transaction Propagation: https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/transaction/annotation/Propagation.html
- ExecutorService: https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/scheduling/concurrent/ThreadPoolTaskExecutor.html

---

## ğŸ Resumen Ejecutivo

El modelo de indexaciÃ³n multithreading para Elasticsearch implementa una arquitectura **Producer-Consumer de 3 capas** (ProducciÃ³n â†’ DistribuciÃ³n â†’ Escritura) con las siguientes caracterÃ­sticas clave:

âœ… **Escalabilidad automÃ¡tica:** Auto-ajuste basado en CPU cores (threads) y cluster Elasticsearch (2-6 writers)  
âœ… **Performance Ã³ptima:** Bulk API reduce 99.8% overhead de red, preload elimina N+1 queries  
âœ… **Resiliencia:** Retry exponencial, partial failure handling, isolation de errores entre threads  
âœ… **Control de flujo:** Semaphore evita saturaciÃ³n BD, BlockingQueues balancean velocidades  
âœ… **Observabilidad:** Logging detallado, mÃ©tricas atÃ³micas, monitoreo de memoria y buffers  
âœ… **SincronizaciÃ³n:** Phaser garantiza flush completo, POISON_PILL para shutdown graceful  

**Throughput estimado:** 500-15,000 docs/seg segÃºn hardware (4-32 cores)  
**ConfiguraciÃ³n recomendada:** Empezar con auto-detect, ajustar solo si hay bottlenecks observados  
**IntegraciÃ³n:** Complementa flujo carga (single-thread) â†’ merge (batch SQL) â†’ indexaciÃ³n (multithread)

**Fecha de anÃ¡lisis:** 8 de enero de 2025  
**Autor:** AnÃ¡lisis tÃ©cnico del sistema de indexaciÃ³n Elasticsearch  
**Enfoque:** ImplementaciÃ³n multithreading para indexaciÃ³n en Elasticsearch  
**Contexto:** Post-refactoring de arquitectura transaccional
